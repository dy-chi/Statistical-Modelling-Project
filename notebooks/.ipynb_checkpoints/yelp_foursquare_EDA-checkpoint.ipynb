{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your tasks are as follows:\n",
    "- Connect to the Foursquare API\n",
    "- Connect to the Yelp API. This API offers similar services as Foursquare.\n",
    "- For each of the bike stations in Part 1, query both APIs to retrieve information for the following in that location:\n",
    "    - Restaurants or bars\n",
    "    - Various POIs (points of interest) of your choice\n",
    " - Create a DataFrame for the Yelp results and Foursquare results.\n",
    " - Compare the quality of the Yelp and Foursquare API. For your location, which API gives you the most complete information/better coverage? NOTE: Your definition of 'coverage' is up to you. It could be simple 'number of POIs in the area', but it could also be something more specific like 'number of reviews per POI', or 'number of different attributes of each POI'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import ast\n",
    "import folium\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the data folder, get a dataframe of all the stations we want yelp/foursquare/usgs data for\n",
    "stations_df=pd.read_csv('data/initial_stations_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabbing empty station dictionary from csv dataframe and converting it into a dictionary\n",
    "stations_empty_df=pd.read_csv('data/stations_empty_df.csv')\n",
    "stations_to_venues_dict_empty=stations_empty_df.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to the Foursquare API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to Foursquare with a small radius (100m) for all the bike stations in your city of choice.\n",
    "- I chose 100m as opposed to 1000, to better model unique \"hilliness\" of the area's venues more directly. There may be too much of a range of distances to get useful information on hilliness if the spread of distances from the station is too great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearby_venues_fs(names, latitudes, longitudes,empty_station_dict):\n",
    "    '''takes columns from a dataframe(series) and returns a dictionary containing the lat long and fsq_id of venues within a certain radius of a bike station also takes an empty dictionary with station ids'''\n",
    "    #get environmental variable for fs key\n",
    "    fs_key_name = 'fourquare_auth'\n",
    "    # Use the os.environ dictionary to access the value of the environmental variable\n",
    "    fs_key_value = os.environ.get(fs_key_name)\n",
    "    # Try to access the dictionary with the specified name, create it if it doesn't exist\n",
    "    filled_station_dict=empty_station_dict.copy()\n",
    "    # Iterate through the provided names, latitudes, and longitudes\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        # Print the current station name\n",
    "        print(name)\n",
    "        \n",
    "        # Part 1: Creating the API request URL\n",
    "        url = \"https://api.foursquare.com/v3/places/search\"\n",
    "        latlong = str(lat) + ',' + str(lng)\n",
    "        params = {\n",
    "            \"ll\": latlong,\n",
    "            \"radius\": 100  # Search radius in meters\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Authorization\": \"fsq3x8GlNfJTXly8FuBH09r407r22hhDIXfvCj/uL8qHZCs=\"\n",
    "        }\n",
    "        \n",
    "        # Part 2: Making the GET request\n",
    "        response = requests.request(\"GET\", url, params=params, headers=headers)\n",
    "        response_dict = response.json()\n",
    "        list_of_venues=[]\n",
    "        list_of_lats=[]\n",
    "        list_of_longs=[]\n",
    "        # Part 3: Processing nearby venues and appending relevant information to the list\n",
    "        for result in response_dict['results']:\n",
    "            if result['fsq_id'] is not None:\n",
    "                list_of_venues.append(result['fsq_id'])\n",
    "                list_of_lats.append(result['geocodes']['main']['latitude'])\n",
    "                list_of_longs.append(result['geocodes']['main']['longitude'])\n",
    "        venue_lat_long_l=list(zip(list_of_venues, list_of_lats, list_of_longs)) \n",
    "        # Store the list of venues in the station_venue_dict using the station name as key\n",
    "        filled_station_dict[name] = venue_lat_long_l\n",
    "        filled_station_dict\n",
    "    # Return the dictionary containing nearby venues for each station\n",
    "    return filled_station_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d0e8f4f1834b7b33a3faf8882f567ab8\n",
      "983514094dd808b1604da2dcfc2d09af\n",
      "da17603652106fda93da4e255a5b0a22\n",
      "7a21c92b3b4cd2f7759107b4fdebf869\n",
      "ce34d38fb230a23c1ced12d1e16df294\n",
      "a3b487ad4ac93ab3e9f9654f87ed8c1e\n",
      "b4b0088fb4fbb4587cad9d89ddc092cd\n",
      "d576652cc151c23d6ec52b8454429d47\n",
      "0a24b6ab9ca6684780b6682901b3c680\n",
      "a4b234ab072402cbfcbd5e306588d9a9\n"
     ]
    }
   ],
   "source": [
    "#run get_nearby_venues_fs function returning a dictionary, with stations as keys and lat, long, ids and items (can be multiple or no venues for a single station) \n",
    "station_venues_FS = get_nearby_venues_fs(names = stations_df['id'].head(10),\n",
    "                                   latitudes = stations_df['latitude'].head(10),\n",
    "                                   longitudes = stations_df['longitude'].head(10),\n",
    "                                    \n",
    "                                   empty_station_dict=stations_to_venues_dict_empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the POI (such as restaurants, bars, etc) details you want (ratings, name, location, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the only information I am grabbing at this point is lat longs and id, in the future I would likely want other info, perhaps ratings or distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orients the dictionary so the rows are the keys (stations)\n",
    "df_fs = pd.DataFrame.from_dict(station_venues_FS, orient='index') \n",
    "#inserts index into a new column 'station_id'\n",
    "df_fs.insert(0, \"station_id\", df_fs.index) \n",
    "#names each column store 1 through n\n",
    "new_columns = [\"station_id\"] + [\"venue_\" + str(i+1) for i in range(df_fs.shape[1]-1)] \n",
    "df_fs.columns=new_columns\n",
    "#resets the index to row numbers\n",
    "df_fs.reset_index(drop=True, inplace=True)\n",
    "df_fs\n",
    "#since I've already done this I will not save the resulting dataframe and rather load a previous one in \n",
    "df_fs=pd.read_csv('data/sanfran_venues_latlong_fs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to Yelp with a small radius (100m) for all the bike stations in San Fran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearby_venues_yelp(names, latitudes, longitudes,empty_station_dict):\n",
    "    '''takes columns from a dataframe(series) and returns a dictionary containing the lat long and id of venues within a certain radius of a bike station also takes an empty dictionary with station ids'''\n",
    "    filled_station_dict=empty_station_dict.copy()\n",
    "    #get environmental variable for yelp key\n",
    "    yelp_key_name = 'yelp_api_auth'\n",
    "    # Use the os.environ dictionary to access the value of the environmental variable\n",
    "    yelp_key_value = os.environ.get(yelp_key_name)    \n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "    \n",
    "        url = \"https://api.yelp.com/v3/businesses/search\"\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"Authorization\": yelp_key_value\n",
    "        }\n",
    "        params = {\n",
    "        \"latitude\":lat,\n",
    "        \"longitude\":lng,\n",
    "        \"radius\":100\n",
    "        } \n",
    "        response = requests.request(\"GET\", url, params=params, headers=headers)\n",
    "        response_dict=response.json()\n",
    "\n",
    "    \n",
    "# Part 3 returning only relevant information for each nearby venue and append to the list\n",
    "        list_of_venues=[]\n",
    "        list_of_lats=[]\n",
    "        list_of_longs=[]\n",
    "        for result in response_dict['businesses']:\n",
    "            if result['id'] is not None:\n",
    "                list_of_venues.append(result['id'])\n",
    "                list_of_lats.append(result['coordinates']['latitude'])\n",
    "                list_of_longs.append(result['coordinates']['longitude'])\n",
    "        venue_lat_long_l=list(zip(list_of_venues, list_of_lats, list_of_longs)) \n",
    "        filled_station_dict[name] = venue_lat_long_l\n",
    "        filled_station_dict\n",
    "    return (filled_station_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the POI (such as restaurants, bars, etc) details you want (ratings, name, location, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the only information I am grabbing at this point is lat longs and id, in the future I would likely want other info, perhaps ratings or distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getNearbyCoffe_Yelp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#returns a dictionary station_Library_Yelp containing  stations as keys and lat, long, ids as items (can be multiple or no venuesfor a single station) \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m station_Library_Yelp \u001b[38;5;241m=\u001b[39m \u001b[43mgetNearbyCoffe_Yelp\u001b[49m(names \u001b[38;5;241m=\u001b[39m stations_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      3\u001b[0m                               latitudes \u001b[38;5;241m=\u001b[39m stations_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      4\u001b[0m                             longitudes \u001b[38;5;241m=\u001b[39m stations_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m      5\u001b[0m                             empty_station_dict\u001b[38;5;241m=\u001b[39mstations_to_venues_dict_empty)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'getNearbyCoffe_Yelp' is not defined"
     ]
    }
   ],
   "source": [
    "#returns a dictionary station_Library_Yelp containing  stations as keys and lat, long, ids as items (can be multiple or no venuesfor a single station) \n",
    "station_Library_Yelp = getNearbyCoffe_Yelp(names = stations_df['id'],\n",
    "                              latitudes = stations_df['latitude'],\n",
    "                            longitudes = stations_df['longitude'], \n",
    "                            empty_station_dict=stations_to_venues_dict_empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orients the dictionary so the rows are the keys (stations)\n",
    "df_yelp = pd.DataFrame.from_dict(station_Library_Yelp, orient='index') \n",
    "#inserts index into a new column 'station_id'\n",
    "df_yelp.insert(0, \"station_id\", df_yelp.index) \n",
    "#names each column library 1 through n\n",
    "new_columns = [\"station_id\"] + [\"store_\" + str(i+1) for i in range(df_yelp.shape[1]-1)] \n",
    "df_yelp.columns=new_columns\n",
    "#resets the index to row numbers\n",
    "df_yelp.reset_index(drop=True, inplace=True)\n",
    "df_yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp=pd.read_csv('data/df_yelp_head_tail_250.csv')\n",
    "\n",
    "df_yelp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab Elevations from USGS \n",
    "### https://epqs.nationalmap.gov/v1/json\n",
    "since there is no elevation data in yelp or fs I went to another source\n",
    "\n",
    "I need to extract only unique lat longs from venue_ids and request them from the usgs api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract unique IDs+lat long  tuples\n",
    "def extract_unique_ids_lat_longs(dataframe):\n",
    "    '''takes a dataframe with only values exactly like ('pn-KO9C7bLiDqfkZiTFqdA', 37.77064, -122.4771) or NaN and returns a set with tuples of unique ids and lat, long '''\n",
    "    unique_ids_lat_longs=set()\n",
    "    for index, row in dataframe.iterrows():\n",
    "        for column in dataframe.columns:\n",
    "            if type(row[column]) == str:\n",
    "                item=row[column]\n",
    "                unique_ids_lat_longs.add(item)\n",
    "    return unique_ids_lat_longs\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "venues_only_df=df_yelp[df_yelp.columns[1:]]\n",
    "venues_only_df\n",
    "yelp_unique_ids_lat_longs=extract_unique_ids_lat_longs(venues_only_df)\n",
    "yelp_unique_ids_lat_longs\n",
    "yelp_unique_ids_lat_longs_list=list(yelp_unique_ids_lat_longs)\n",
    "\n",
    "\n",
    "df_unique_yelp_ids_latlong = pd.DataFrame({'ID_LAT_LONG': yelp_unique_ids_lat_longs_list})\n",
    "df_unique_yelp_ids_latlong.head(5)\n",
    "#df_unique_yelp_ids_latlong.to_csv('data/df_unique_yelp_ids_latlong.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_yelp_ids_latlong=pd.read_csv('data/df_unique_yelp_ids_latlong.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elev(names, latitudes, longitudes):\n",
    "    '''takes id string, lat and long in as floats and returns a list '''\n",
    "    # Create an empty list to hold the entries\n",
    "    lat_long_list = []\n",
    "    response = requests.get(\"https://epqs.nationalmap.gov/v1/json?x=-122&y=30&wkid=4326&units=Meters&includeDate=false\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "            print(name)\n",
    "            url = \"https://epqs.nationalmap.gov/v1/json\"\n",
    "            params = {\n",
    "                \"x\": lng,\n",
    "                \"y\": lat,\n",
    "                \"wkid\": 4326,\n",
    "                \"units\": \"Meters\",\n",
    "                \"includeDate\": True\n",
    "            }\n",
    "\n",
    "            response = requests.get(url, params=params)\n",
    "            response_dict = response.json()\n",
    "\n",
    "\n",
    "            entry = {\n",
    "                'Station_ID': name,\n",
    "                'Longitude': response_dict['location']['x'],\n",
    "                'Latitude': response_dict['location']['y'],\n",
    "                'Elevation': response_dict['value']\n",
    "            }\n",
    "            lat_long_list.append(entry)\n",
    "            print(response_dict['location']['y'], response_dict['location']['x'], response_dict['value'])\n",
    "            #saving each request in case there are errors during the request, so we can start over from where the error occured\n",
    "            #pd.DataFrame(lat_long_list).to_csv('to416df_unique_yelp_ids_latlong_elev.csv', index=False)\n",
    "    else:\n",
    "        print(\"Request failed with status code:\", response.status_code)\n",
    "    \n",
    "    return lat_long_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the get elev function from rows 1 to 416, as the row in 417 was causing errors, repeat this process until all venues have elevations\n",
    "df_unique_yelp_ids_latlong_elev = get_elev(names = df_unique_yelp_ids_latlong['ID_LAT_LONG'][:416].apply(lambda x: x[0]),\n",
    "                             latitudes = df_unique_yelp_ids_latlong['ID_LAT_LONG'][:416].apply(lambda x: x[1]),\n",
    "                            longitudes = df_unique_yelp_ids_latlong['ID_LAT_LONG'][:416].apply(lambda x: x[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of combing results of multiple requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_df = pd.concat([to416_df_unique_yelp_ids_latlong_elev_df, to2525_df_unique_yelp_ids_latlong_elev_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_yelp_ids_latlong_elev=pd.read_csv('data/df_unique_yelp_ids_latlong_elev.csv')\n",
    "df_unique_yelp_ids_latlong_elev.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which API provided you with more complete data? Provide an explanation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yelp has a greater number of businesses and other venues in there database accessible to their API. Some of these locations might be out of businesses, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp = pd.read_csv('data/df_yelp_head_tail_250.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fs=pd.read_csv('data/sanfran_venues_latlong_fs.csv')\n",
    "df_fs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count how many venues are found within 100m of each station for foursquare\n",
    "df_fs['NonNullCount'] = df_fs.apply(lambda row: row.count(), axis=1)\n",
    "#Count how many venues are found within 100m of each station for yelp\n",
    "df_yelp['NonNullCount'] = df_yelp.apply(lambda row: row.count(), axis=1)\n",
    "df_yelp[['station_id', 'NonNullCount']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_fs_hits=df_fs['NonNullCount'].head(250).sum()\n",
    "total_yelp_hits=df_yelp['NonNullCount'].head(250).sum()\n",
    "print(f\"total yelp hits: {total_yelp_hits}\")\n",
    "print(f\"total foursquare hits: {total_fs_hits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yelp found more than double the venues within 100m of a station in San Francisco. I will therefore ignore the foursquare results for the remainder of the project going forward and focus on the yelp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat_elevs=pd.read_csv('data/Station_Elevations.csv')\n",
    "\n",
    "stat_elevs.rename(columns={'Station_ID':'station_id'}, inplace=True)\n",
    "stat_elevs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat_elevs['elevation'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_elevs['elevation'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram shows that stations elevation is not normaly distributed, but rather left weighted.\n",
    "\n",
    "There is however a significant range of elevations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp.merge(stat_elevs, on='station_id', how='left').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_venue_elev=pd.read_csv('data/yelp_venue_elev.csv')\n",
    "yelp_venue_elev.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the top 10 highest venues in terms of elevation (modified question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_elevations = yelp_venue_elev.nlargest(10, 'Elevation')\n",
    "top_10_elevations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest venue is \"Roli Roti Gourmet Rotisserie\" with business id 7riqoD4pIgG3mTcUPbe4iA at Moraga Ave And La Salle Ave in the east of Oakland at 185m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_elevs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marker_color(value, min_value, max_value):\n",
    "    norm = colors.Normalize(vmin=min_value, vmax=max_value)\n",
    "    cmap = cm.get_cmap('viridis')  # Choose a colormap (e.g., 'viridis')\n",
    "    rgba_color = cmap(norm(value))\n",
    "    hex_color = colors.rgb2hex(rgba_color)\n",
    "    return hex_color\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folium Map of Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "latitude = 37.766137\n",
    "longitude = -122.347527\n",
    "\n",
    "map_san_fran = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "min_value = stat_elevs['elevation'].min()\n",
    "max_value = stat_elevs['elevation'].max()\n",
    "# add markers to map\n",
    "for station, lat, lng, elev in zip(stat_elevs['station_id'], stat_elevs['latitude'], stat_elevs['longitude'],stat_elevs['elevation']):\n",
    "    label = '{}'.format(station)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=3,\n",
    "        popup=label,\n",
    "        color=get_marker_color(elev, min_value, max_value),\n",
    "        fill=True,\n",
    "        fill_color=get_marker_color(elev, min_value, max_value),\n",
    "        fill_opacity=1,\n",
    "        parse_html=False).add_to(map_san_fran)  \n",
    "    \n",
    "map_san_fran"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhl_base_env",
   "language": "python",
   "name": "lhl_base_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
